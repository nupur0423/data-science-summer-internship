{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''ML classification algorithms(logistic regression, naive bayes, knn, decision tree, random forest, gradient boosting)\n",
        "on iris and titanic dataset - 18/06/2024'''\n",
        "\n",
        "#Find algo with best accuracy for both datasets"
      ],
      "metadata": {
        "id": "IqpSOinQK5vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracies for all the algorithms on Iris Dataset:\n",
        "'''\n",
        "1. Logistic Regression= 0.9777\n",
        "2. Naive Bayes= 0.9333\n",
        "3. KNN= 0.95\n",
        "4. Decision Tree= 0.9777\n",
        "5. Random Forest= 0.9777\n",
        "6. Gradient Boosting= 1.0\n",
        "'''"
      ],
      "metadata": {
        "id": "r7w5LvZRSlje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qksi-vWoS6E",
        "outputId": "da300465-895f-48a4-f696-0eee699fc804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "118            7.7           2.6            6.9           2.3\n",
            "18             5.7           3.8            1.7           0.3\n",
            "4              5.0           3.6            1.4           0.2\n",
            "45             4.8           3.0            1.4           0.3\n",
            "59             5.2           2.7            3.9           1.4\n",
            "..             ...           ...            ...           ...\n",
            "133            6.3           2.8            5.1           1.5\n",
            "137            6.4           3.1            5.5           1.8\n",
            "72             6.3           2.5            4.9           1.5\n",
            "140            6.7           3.1            5.6           2.4\n",
            "37             4.9           3.1            1.5           0.1\n",
            "\n",
            "[105 rows x 4 columns]\n",
            "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "14             5.8           4.0            1.2           0.2\n",
            "98             5.1           2.5            3.0           1.1\n",
            "75             6.6           3.0            4.4           1.4\n",
            "16             5.4           3.9            1.3           0.4\n",
            "131            7.9           3.8            6.4           2.0\n",
            "56             6.3           3.3            4.7           1.6\n",
            "141            6.9           3.1            5.1           2.3\n",
            "44             5.1           3.8            1.9           0.4\n",
            "29             4.7           3.2            1.6           0.2\n",
            "120            6.9           3.2            5.7           2.3\n",
            "94             5.6           2.7            4.2           1.3\n",
            "5              5.4           3.9            1.7           0.4\n",
            "102            7.1           3.0            5.9           2.1\n",
            "51             6.4           3.2            4.5           1.5\n",
            "78             6.0           2.9            4.5           1.5\n",
            "42             4.4           3.2            1.3           0.2\n",
            "92             5.8           2.6            4.0           1.2\n",
            "66             5.6           3.0            4.5           1.5\n",
            "31             5.4           3.4            1.5           0.4\n",
            "35             5.0           3.2            1.2           0.2\n",
            "90             5.5           2.6            4.4           1.2\n",
            "84             5.4           3.0            4.5           1.5\n",
            "77             6.7           3.0            5.0           1.7\n",
            "40             5.0           3.5            1.3           0.3\n",
            "125            7.2           3.2            6.0           1.8\n",
            "99             5.7           2.8            4.1           1.3\n",
            "33             5.5           4.2            1.4           0.2\n",
            "19             5.1           3.8            1.5           0.3\n",
            "73             6.1           2.8            4.7           1.2\n",
            "146            6.3           2.5            5.0           1.9\n",
            "91             6.1           3.0            4.6           1.4\n",
            "135            7.7           3.0            6.1           2.3\n",
            "69             5.6           2.5            3.9           1.1\n",
            "128            6.4           2.8            5.6           2.1\n",
            "114            5.8           2.8            5.1           2.4\n",
            "48             5.3           3.7            1.5           0.2\n",
            "53             5.5           2.3            4.0           1.3\n",
            "28             5.2           3.4            1.4           0.2\n",
            "54             6.5           2.8            4.6           1.5\n",
            "108            6.7           2.5            5.8           1.8\n",
            "112            6.8           3.0            5.5           2.1\n",
            "17             5.1           3.5            1.4           0.3\n",
            "119            6.0           2.2            5.0           1.5\n",
            "103            6.3           2.9            5.6           1.8\n",
            "58             6.6           2.9            4.6           1.3\n",
            "118     Iris-virginica\n",
            "18         Iris-setosa\n",
            "4          Iris-setosa\n",
            "45         Iris-setosa\n",
            "59     Iris-versicolor\n",
            "            ...       \n",
            "133     Iris-virginica\n",
            "137     Iris-virginica\n",
            "72     Iris-versicolor\n",
            "140     Iris-virginica\n",
            "37         Iris-setosa\n",
            "Name: Species, Length: 105, dtype: object\n",
            "14         Iris-setosa\n",
            "98     Iris-versicolor\n",
            "75     Iris-versicolor\n",
            "16         Iris-setosa\n",
            "131     Iris-virginica\n",
            "56     Iris-versicolor\n",
            "141     Iris-virginica\n",
            "44         Iris-setosa\n",
            "29         Iris-setosa\n",
            "120     Iris-virginica\n",
            "94     Iris-versicolor\n",
            "5          Iris-setosa\n",
            "102     Iris-virginica\n",
            "51     Iris-versicolor\n",
            "78     Iris-versicolor\n",
            "42         Iris-setosa\n",
            "92     Iris-versicolor\n",
            "66     Iris-versicolor\n",
            "31         Iris-setosa\n",
            "35         Iris-setosa\n",
            "90     Iris-versicolor\n",
            "84     Iris-versicolor\n",
            "77     Iris-versicolor\n",
            "40         Iris-setosa\n",
            "125     Iris-virginica\n",
            "99     Iris-versicolor\n",
            "33         Iris-setosa\n",
            "19         Iris-setosa\n",
            "73     Iris-versicolor\n",
            "146     Iris-virginica\n",
            "91     Iris-versicolor\n",
            "135     Iris-virginica\n",
            "69     Iris-versicolor\n",
            "128     Iris-virginica\n",
            "114     Iris-virginica\n",
            "48         Iris-setosa\n",
            "53     Iris-versicolor\n",
            "28         Iris-setosa\n",
            "54     Iris-versicolor\n",
            "108     Iris-virginica\n",
            "112     Iris-virginica\n",
            "17         Iris-setosa\n",
            "119     Iris-virginica\n",
            "103     Iris-virginica\n",
            "58     Iris-versicolor\n",
            "Name: Species, dtype: object\n",
            "0.9777777777777777\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        14\n",
            "Iris-versicolor       1.00      0.94      0.97        18\n",
            " Iris-virginica       0.93      1.00      0.96        13\n",
            "\n",
            "       accuracy                           0.98        45\n",
            "      macro avg       0.98      0.98      0.98        45\n",
            "   weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "[[14  0  0]\n",
            " [ 0 17  1]\n",
            " [ 0  0 13]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "#1. Logistic Regression on Iris Dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "logr=LogisticRegression()\n",
        "\n",
        "df=pd.read_csv(\"Iris.csv\")\n",
        "\n",
        "x = df.drop('Id', axis=1)\n",
        "x = x.drop('Species', axis=1)\n",
        "y = df['Species']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y,random_state=1,test_size=0.3)\n",
        "\n",
        "print(X_train)\n",
        "print(X_test)\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n",
        "logr.fit(X_train,y_train)\n",
        "\n",
        "y_pred=logr.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Naive Bayes Classifier on Iris Dataset\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.4)\n",
        "\n",
        "nb = GaussianNB()\n",
        "\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred1 = nb.predict(X_test)\n",
        "\n",
        "print(\"Naive Bayes accuracy: \", accuracy_score(y_test, y_pred1))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred1))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACUn2BA7FvSP",
        "outputId": "f7175dda-360f-42f5-b8a1-2a1dcf7da146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy:  0.9333333333333333\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.85      1.00      0.92        23\n",
            "           2       1.00      0.81      0.89        21\n",
            "\n",
            "    accuracy                           0.93        60\n",
            "   macro avg       0.95      0.94      0.94        60\n",
            "weighted avg       0.94      0.93      0.93        60\n",
            "\n",
            "Confusion matrix:\n",
            " [[16  0  0]\n",
            " [ 0 23  0]\n",
            " [ 0  4 17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. KNN on Iris Dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['species'] = iris.target\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "x = df.drop('species', axis=1)\n",
        "y = df['species']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.4)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "print(\"KNN Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_4KtlYUGl9q",
        "outputId": "a4c2536b-4b05-442e-bb72-e608bac85759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   species  \n",
            "0        0  \n",
            "1        0  \n",
            "2        0  \n",
            "3        0  \n",
            "4        0  \n",
            "KNN Accuracy:  0.95\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.92      0.96      0.94        23\n",
            "           2       0.95      0.90      0.93        21\n",
            "\n",
            "    accuracy                           0.95        60\n",
            "   macro avg       0.96      0.95      0.95        60\n",
            "weighted avg       0.95      0.95      0.95        60\n",
            "\n",
            "Confusion matrix:\n",
            " [[16  0  0]\n",
            " [ 0 22  1]\n",
            " [ 0  2 19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Decision Tree on Iris Dataset\n",
        "\n",
        "from sklearn import datasets, tree\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.3)\n",
        "\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl-c7mBvGpnp",
        "outputId": "45a052f9-f363-4ad8-d2a6-d56e534a2492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy:  0.9777777777777777\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       1.00      0.94      0.97        18\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.97      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "Confusion matrix:\n",
            " [[16  0  0]\n",
            " [ 0 17  1]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Random Forest on Iris Dataset\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.3)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcynOOjOGzw4",
        "outputId": "d2bec632-03e4-45f8-c531-c9004edcba95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy:  0.9777777777777777\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       1.00      0.94      0.97        18\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.97      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "Confusion matrix:\n",
            " [[16  0  0]\n",
            " [ 0 17  1]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Gradient Boosting on Iris Dataset\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "gbm = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
        "\n",
        "gbm.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = gbm.predict(X_test)\n",
        "\n",
        "print(\"GBM Accuracy: \", accuracy_score(Y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQbGb8jPG3QA",
        "outputId": "f5d918d9-bb95-45e1-9ef7-a99931883b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBM Accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracies for all the algorithms on Titanic Dataset:\n",
        "'''\n",
        "1. Logistic Regression= 1.0\n",
        "2. Naive Bayes= 1.0\n",
        "3. KNN= 0.9841\n",
        "4. Decision Tree= 1.0\n",
        "5. Random Forest= 1.0\n",
        "6. Gradient Boosting= 1.0\n",
        "'''"
      ],
      "metadata": {
        "id": "JwHusa-NS9ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Logistic Regression on Titanic Dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "logr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "df = pd.read_csv(\"Titanic.csv\")\n",
        "print(df.head())\n",
        "\n",
        "x = df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "x = pd.get_dummies(x, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "x['Age'].fillna(x['Age'].mean(), inplace=True)\n",
        "x['Fare'].fillna(x['Fare'].mean(), inplace=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.3)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n",
        "\n",
        "logr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logr.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inM65bIUHJcC",
        "outputId": "a579ce99-b3fe-4258-8471-3c709ce56bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "Training set shape: (292, 8)\n",
            "Testing set shape: (126, 8)\n",
            "Accuracy score: 1.0\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        85\n",
            "           1       1.00      1.00      1.00        41\n",
            "\n",
            "    accuracy                           1.00       126\n",
            "   macro avg       1.00      1.00      1.00       126\n",
            "weighted avg       1.00      1.00      1.00       126\n",
            "\n",
            "Confusion matrix:\n",
            " [[85  0]\n",
            " [ 0 41]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Naive Bayes Classifier on Titanic Dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"Titanic.csv\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "x = df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "x = pd.get_dummies(x, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "x['Age'].fillna(x['Age'].mean(), inplace=True)\n",
        "x['Fare'].fillna(x['Fare'].mean(), inplace=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.4)\n",
        "\n",
        "nb = GaussianNB()\n",
        "\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred1 = nb.predict(X_test)\n",
        "\n",
        "print(\"Naive Bayes Accuracy: \", accuracy_score(y_test, y_pred1))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred1))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd9f8cg_I14W",
        "outputId": "18298574-cbde-4e74-92e5-06520f7c28ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "Naive Bayes Accuracy:  1.0\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        93\n",
            "           1       1.00      1.00      1.00        75\n",
            "\n",
            "    accuracy                           1.00       168\n",
            "   macro avg       1.00      1.00      1.00       168\n",
            "weighted avg       1.00      1.00      1.00       168\n",
            "\n",
            "Confusion matrix:\n",
            " [[93  0]\n",
            " [ 0 75]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. KNN on Titanic Dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"Titanic.csv\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "x = df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "x = pd.get_dummies(x, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "x['Age'].fillna(x['Age'].mean(), inplace=True)\n",
        "x['Fare'].fillna(x['Fare'].mean(), inplace=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.3)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "print(\"KNN Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkyA3US0Jt_S",
        "outputId": "c535890c-c7dd-46fa-a86f-94dcde518cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "KNN Accuracy:  0.9841269841269841\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99        71\n",
            "           1       0.98      0.98      0.98        55\n",
            "\n",
            "    accuracy                           0.98       126\n",
            "   macro avg       0.98      0.98      0.98       126\n",
            "weighted avg       0.98      0.98      0.98       126\n",
            "\n",
            "Confusion matrix:\n",
            " [[70  1]\n",
            " [ 1 54]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Decision Tree on Titanic Dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"Titanic.csv\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "x = df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "x = pd.get_dummies(x, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "x['Age'].fillna(x['Age'].mean(), inplace=True)\n",
        "x['Fare'].fillna(x['Fare'].mean(), inplace=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.3)\n",
        "\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl9EKgq-KORp",
        "outputId": "4c6db52c-1605-4970-a380-03f060907376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "Decision Tree Accuracy:  1.0\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        71\n",
            "           1       1.00      1.00      1.00        55\n",
            "\n",
            "    accuracy                           1.00       126\n",
            "   macro avg       1.00      1.00      1.00       126\n",
            "weighted avg       1.00      1.00      1.00       126\n",
            "\n",
            "Confusion matrix:\n",
            " [[71  0]\n",
            " [ 0 55]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Random Forest on Titanic Dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"Titanic.csv\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "x = df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "x = pd.get_dummies(x, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "x['Age'].fillna(x['Age'].mean(), inplace=True)\n",
        "x['Fare'].fillna(x['Fare'].mean(), inplace=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.3)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9xyEcyCKdK7",
        "outputId": "f71dbb42-15f7-4700-f5d1-217fd4cc2380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "Random Forest Accuracy:  1.0\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        71\n",
            "           1       1.00      1.00      1.00        55\n",
            "\n",
            "    accuracy                           1.00       126\n",
            "   macro avg       1.00      1.00      1.00       126\n",
            "weighted avg       1.00      1.00      1.00       126\n",
            "\n",
            "Confusion matrix:\n",
            " [[71  0]\n",
            " [ 0 55]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Gradient Boosting on Titanic Dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"Titanic.csv\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "x = df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "x = pd.get_dummies(x, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "x['Age'].fillna(x['Age'].mean(), inplace=True)\n",
        "x['Fare'].fillna(x['Fare'].mean(), inplace=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, random_state=0, test_size=0.2)\n",
        "\n",
        "gbm = GradientBoostingClassifier(n_estimators=10)\n",
        "\n",
        "gbm.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = gbm.predict(X_test)\n",
        "\n",
        "print(\"GBM Accuracy: \", accuracy_score(Y_test, y_pred))\n",
        "\n",
        "print(\"Classification report:\\n\", classification_report(Y_test, y_pred))\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(Y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_yvP_GlKk9o",
        "outputId": "2845dfd9-7b8d-44aa-98eb-44abd4603562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "GBM Accuracy:  1.0\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        45\n",
            "           1       1.00      1.00      1.00        39\n",
            "\n",
            "    accuracy                           1.00        84\n",
            "   macro avg       1.00      1.00      1.00        84\n",
            "weighted avg       1.00      1.00      1.00        84\n",
            "\n",
            "Confusion matrix:\n",
            " [[45  0]\n",
            " [ 0 39]]\n"
          ]
        }
      ]
    }
  ]
}